{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 input neurons in the input layer\n",
    "# 2 hidden layers with 6 neurons each\n",
    "# 2 output neurons in the output layer\n",
    "# all activation functions are sigmoid\n",
    "\n",
    "\n",
    "dataset_unfiltered = np.array([\n",
    "\t[0,\t\t0,\t\t0,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t0,\t\t1,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t0,\t\t1,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t1,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t1,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t1,\t\t1,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t1,\t\t1,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t1,\t\t0,\t\t0,\t\t0,\t\t1,\t\t0],\n",
    "\t[0,\t\t1,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t1,\t\t0,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[0,\t\t1,\t\t0,\t\t1,\t\t1,\t\t1,\t\t0],\n",
    "\t[0,\t\t1,\t\t1,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t1,\t\t1,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t1,\t\t1,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[0,\t\t1,\t\t1,\t\t1,\t\t1,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t0,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[1,\t\t0,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[1,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t0,\t\t1,\t\t1,\t\t0,\t\t1],\n",
    "\t[1,\t\t0,\t\t1,\t\t0,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t1,\t\t0,\t\t1,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t1,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t1,\t\t1,\t\t1,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t0,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[1,\t\t1,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[1,\t\t1,\t\t0,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t0,\t\t1,\t\t1,\t\t0,\t\t1],\n",
    "\t[1,\t\t1,\t\t1,\t\t0,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t1,\t\t0,\t\t1,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t1,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t1,\t\t1,\t\t1,\t\t1,\t\t0]\n",
    "\t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRandom2DMatrix(m, n):\n",
    "\treturn [ [random.randint(1,100)/100 for k in range(n)] for i in range(m) ]\n",
    "\n",
    "def sigmoid(z):\n",
    "\treturn 1/(1+np.exp(-z))\n",
    "\n",
    "def CostFunction(NN_output,output):\n",
    "\treturn output*(np.log10(NN_output)) + (1-output)*(np.log10(1 - NN_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = [ [0 for k in range(6)] for i in range(len(dataset_unfiltered)) ]\n",
    "index_data_set = 0\n",
    "\n",
    "\n",
    "\n",
    "for k in range(len(dataset_unfiltered[:,0])):\n",
    "\n",
    "\tfor i in range(dataset_unfiltered[k][5]):\n",
    "\t\t#temp = np.append( dataset_unfiltered[k][0:5], 1)\n",
    "\t\tdata_set[index_data_set] = np.append( dataset_unfiltered[k][0:5], 1)\n",
    "\t\tindex_data_set += 1\n",
    "\n",
    "\tfor j in range(dataset_unfiltered[k][6]):\n",
    "\t\t#temp = dataset_unfiltered[k][0:5]\n",
    "\t\tdata_set[index_data_set] = np.append( dataset_unfiltered[k][0:5], 0)\n",
    "\t\tindex_data_set += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training dataset and testing dataset:\n",
    "# But first, we need to shuffle the entire dataset!\n",
    "\n",
    "random.seed(99)\n",
    "random.shuffle(data_set)\n",
    "\n",
    "training_data_set = data_set[0:(math.ceil(0.70*len(data_set)))]\n",
    "testing_data_set  =\tdata_set[(math.ceil(0.70*len(data_set))): len(data_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:    23\n",
      "Testing dataset:     9\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset:   \", len(training_data_set))\n",
    "print(\"Testing dataset:    \", len(testing_data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [ [0 for k in range(5)] for i in range(len(training_data_set)) ]\n",
    "desired_outputs = [0 for k in range(len(training_data_set))]\n",
    "\n",
    "\n",
    "inputs_testing = [ [0 for k in range(5)] for i in range(len(testing_data_set)) ]\n",
    "desired_outputs_testing = [0 for k in range(len(testing_data_set))]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(training_data_set)):\n",
    "\tinputs[i] = training_data_set[i][0:5]\n",
    "\tdesired_outputs[i] = training_data_set[i][5]\n",
    "\n",
    "for i in range(len(testing_data_set)):\n",
    "\tinputs_testing[i] = training_data_set[i][0:5]\n",
    "\tdesired_outputs_testing[i] = training_data_set[i][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_space = 1\n",
    "\n",
    "nInputs_neurons = 5 \n",
    "nNeurons_second_layer = 6 \n",
    "nNeurons_third_layer  = 6 \n",
    "output_neurons = 1 \n",
    "\n",
    "nInputs_neurons += bias_space\n",
    "nNeurons_second_layer += bias_space\n",
    "nNeurons_third_layer  += bias_space\n",
    "output_neurons += bias_space     # Not needed but will does make the algorith easier to write. We will ignore the bias here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights = [ [] for i in range(3)]\n",
    "\n",
    "#the first column is the Bias. So it will be set to 1.\n",
    "Weights[0] = np.array(generateRandom2DMatrix(nNeurons_second_layer, nInputs_neurons ))\n",
    "Weights[1] = np.array(generateRandom2DMatrix(nNeurons_third_layer, nNeurons_second_layer ))\n",
    "Weights[2] = np.array(generateRandom2DMatrix(output_neurons, nNeurons_third_layer ))\n",
    "\n",
    "Weights = np.array(Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = [ 0 for i in range(nInputs_neurons)]\n",
    "first_hidden_layer = [ 0 for i in range(nNeurons_second_layer)]\n",
    "second_hidden_layer = [ 0 for i in range(nNeurons_third_layer)]\n",
    "output_layer = [ 0 for i in range(output_neurons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are bias\n",
    "input_layer = np.append(1, inputs[0])\n",
    "first_hidden_layer[0] = 1\n",
    "second_hidden_layer[0] = 1\n",
    "\n",
    "neurons = [input_layer, first_hidden_layer, second_hidden_layer, output_layer]\n",
    "neurons = (neurons)\n",
    "#neuron[\"layer\"][\"Which neuron of the layer/ FIRST ONE IS THE BIAS\"]\n",
    "neurons[0][0] = 1\n",
    "neurons[1][0] = 1\n",
    "neurons[2][0] = 1\n",
    "neurons[3][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropagation(data_number = 0, training_data = True, showComputation = False, matrix_neurons = neurons, W = Weights):\n",
    "\tif(training_data == True):\n",
    "\t\tinput_i = inputs[data_number]\n",
    "\telse:\n",
    "\t\tinput_i = inputs_testing[data_number]\n",
    "\n",
    "\tmatrix_neurons[0] = np.append(1 , input_i)\n",
    "\tmatrix_neurons[1][0] = 1\n",
    "\tmatrix_neurons[2][0] = 1\n",
    "\tmatrix_neurons[3][0] = 1\n",
    "\t\n",
    "\tif(showComputation == True):\n",
    "\t\tprint(matrix_neurons)\n",
    "\n",
    "\tfor layer in range(len(W)):\n",
    "\t\tfor neuron_j in range(len(matrix_neurons[layer+1])):\n",
    "\t\t\tnext_layer_neuron = layer + 1\n",
    "\t\t\tz_j = np.dot( matrix_neurons[layer] , W[layer][neuron_j,:] )\n",
    "\t\t\tmatrix_neurons[next_layer_neuron][neuron_j] = sigmoid(z_j)\n",
    "\t\t\tif(showComputation == True):\n",
    "\t\t\t\tprint(matrix_neurons[layer] ,\" . \" , W[layer][neuron_j,:], \"  = s([\",next_layer_neuron, \"][\",neuron_j,\"]]) = \", sigmoid(z_j))\n",
    "\t\t\t\tprint(\"\")\n",
    "\n",
    "\tmatrix_neurons[1][0] = 1\n",
    "\tmatrix_neurons[2][0] = 1\n",
    "\tmatrix_neurons[3][0] = 1\n",
    "\n",
    "\treturn matrix_neurons, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs         :         [1 1 1 0 0 0]\n",
      "Hidden layer 1 :         [1, 0.6963549298238342, 0.8220063142137535, 0.7130001627522816, 0.8277836082661223, 0.5572478545985555, 0.7685247834990178]\n",
      "Hidden layer 2 :         [1, 0.8872244509440987, 0.9612400717011033, 0.9721735867571986, 0.8320721031373728, 0.8700163598547583, 0.9234753293152094]\n",
      "Outputs        :         [1, 0.923769115516216]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "forwardPropagation(0)\n",
    "\n",
    "\n",
    "def printNeurons(matrix_neurons = neurons):\n",
    "\tlayer_names = [\"Inputs        \", \"Hidden layer 1\", \"Hidden layer 2\", \"Outputs       \"]\n",
    "\tfor i in range(len(matrix_neurons)):\n",
    "\t\tprint(layer_names[i] , \":        \", matrix_neurons[i])\n",
    "        \n",
    "    \n",
    "printNeurons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing delta\n",
    "def get_copy_of_neurons_matrix_null(matrix):\n",
    "\tm = matrix.copy()\n",
    "\tfor i in range(len(m)):\n",
    "\t\tm[i] = np.matrix(m[i])\n",
    "\t\tm[i].fill(0)\n",
    "\treturn m\n",
    "\n",
    "\n",
    "\n",
    "delta_error_matrix = get_copy_of_neurons_matrix_null(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDeltaMatrix(training_example = 0, showComputation = False, W = Weights, matrix_neurons = neurons, Delt = delta_error_matrix):\n",
    "\t\n",
    "\tif(showComputation == True):\n",
    "\t\tprint(\"STARTING: \")\n",
    "\t#training_example = 1000\n",
    "\tinput_i = inputs[training_example] \n",
    "\tdesired_outputs_i = desired_outputs[training_example]\n",
    "\n",
    "\tif(showComputation == True):\n",
    "\t\tprint(W)\n",
    "\t\tprint(\"Training example: \", training_example)\n",
    "\t\tprint(\"Inputs and outputs: \", input_i, desired_outputs_i)\n",
    "\n",
    "\tfor layer in reversed(range(1,len(matrix_neurons))):\n",
    "\t\tif(showComputation == True):\n",
    "\t\t\tprint(layer)\n",
    "\t\tif(layer == len(matrix_neurons) - 1):\n",
    "\t\t\tif(showComputation == True):\n",
    "\t\t\t\tprint(np.subtract(matrix_neurons[layer][1:len(matrix_neurons[layer])] , desired_outputs_i))\n",
    "\t\t\tDelt[layer] = np.subtract(matrix_neurons[layer][1:len(matrix_neurons[layer])] , desired_outputs_i)\n",
    "\t\t\tDelt[layer] = np.append(0, Delt[layer])\n",
    "\t\telse:\n",
    "\t\t\t\tw = W[layer].copy() #[1:len(W[layer])].copy()\n",
    "\t\t\t\t\n",
    "\t\t\t\tw_T = w.transpose() \n",
    "\t\t\t\tif(showComputation == True):\n",
    "\t\t\t\t\tprint(\"w: \", w)\n",
    "\t\t\t\t\tprint(\"w_T:\")\n",
    "\t\t\t\t\tprint(w_T)\n",
    "\t\t\t\t\tprint(\"delta \",layer + 1,\":\" )\n",
    "\t\t\t\t\tprint(Delt[layer + 1])\n",
    "\t\t\t\tx = np.matmul(w_T, Delt[layer + 1])\n",
    "\t\t\t\t#x = x[1:len(x)]\n",
    "\n",
    "\t\t\t\t# Derivative_Sigmoid_of_neuron_layer(z) = neurons_of_layer*(1-neurons_of_layer)\n",
    "\t\t\t\tneurons_of_layer = np.array(matrix_neurons[layer].copy())#[1:len(matrix_neurons[layer])].copy())\n",
    "\t\t\t\tvector_of_one \t = np.array(neurons_of_layer.copy())\n",
    "\t\t\t\tvector_of_one.fill(1)\n",
    "\t\t\t\ty = np.subtract(vector_of_one, neurons_of_layer)\n",
    "\t\t\t\tDerivative_Sigmoid_of_neuron_layer = np.multiply(neurons_of_layer , y)\n",
    "\n",
    "\t\t\t\t# Putting the whole equation together:\n",
    "\t\t\t\tDelt[layer] = np.multiply(x , Derivative_Sigmoid_of_neuron_layer)\n",
    "\t\tif(showComputation == True):\n",
    "\t\t\tprint(\"delta[\",layer,\"]\", Delt[layer])\n",
    "\treturn Delt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = computeDeltaMatrix() \n",
    "#print(np.matrix(delta))\n",
    "\n",
    "\n",
    "def training(nomber_of_training_set = len(training_data_set), matrix_neurons = neurons, W = Weights, regularization_param = 5):\n",
    "\tmat_weights_null = get_copy_of_neurons_matrix_null(W)\n",
    "\t\n",
    "\tfor training_set in range(nomber_of_training_set):\n",
    "\t\t#print(training_set)\n",
    "\t\tmatrix_neurons, W \t= forwardPropagation(training_set, True, False, matrix_neurons, W)\n",
    "\t\tdelta \t\t\t\t= computeDeltaMatrix(training_set)\n",
    "\n",
    "\t\t# Backpropagation algorithm\n",
    "\t\tfor layer in reversed(range(1, len(matrix_neurons))):\n",
    "\t\t\tneuron_vector = neurons[layer-1].copy()\n",
    "\t\t\tdelta_vector  = delta[layer].copy()\n",
    "\n",
    "\t\t\tneuron_vector = np.matrix(neuron_vector)\n",
    "\t\t\tdelta_vector  = np.matrix(delta_vector).transpose()\n",
    "\n",
    "\t\t\tmultiplication_term = np.matmul(delta_vector, neuron_vector)\n",
    "\t\t\tmat_weights_null[layer-1] = mat_weights_null[layer-1] + multiplication_term\n",
    "\n",
    "\tc = (1/nomber_of_training_set)\n",
    "\t#derivative_J = (1/nomber_of_training_set)*mat_weights_null\n",
    "\tderivatives_Cost_Weight = get_copy_of_neurons_matrix_null(W)\n",
    "\n",
    "\tfor layer in range(len(mat_weights_null)):\n",
    "\t\tfor m in range(len(mat_weights_null[layer][:,0])):\n",
    "\t\t\tfor n in range(len(mat_weights_null[layer][0,:])):\n",
    "\t\t\t\tif(n != 0):\n",
    "\t\t\t\t\tderivatives_Cost_Weight[layer][m][n] = c*mat_weights_null[layer][m][n] + regularization_param*W[layer][m][n]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tderivatives_Cost_Weight[layer][m][n] = c*mat_weights_null[layer][m][n]\n",
    "\treturn derivatives_Cost_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.61, 0.41, 0.52, 0.06, 0.35, 0.72],\n",
      "       [0.01, 0.55, 0.27, 0.47, 0.69, 0.11],\n",
      "       [0.6 , 0.67, 0.26, 0.78, 0.6 , 0.07],\n",
      "       [0.46, 0.17, 0.28, 0.92, 0.21, 0.96],\n",
      "       [0.57, 0.77, 0.23, 0.65, 0.85, 0.23],\n",
      "       [0.05, 0.15, 0.03, 0.22, 0.61, 0.88],\n",
      "       [0.54, 0.11, 0.55, 0.81, 0.12, 0.19]])\n",
      " array([[0.4 , 0.8 , 0.01, 0.49, 0.43, 0.18, 0.67],\n",
      "       [0.52, 0.26, 0.08, 0.82, 0.28, 0.57, 0.33],\n",
      "       [0.7 , 0.52, 0.98, 0.17, 0.46, 0.89, 0.61],\n",
      "       [0.08, 0.17, 0.95, 0.92, 0.77, 1.  , 0.96],\n",
      "       [0.2 , 0.78, 0.53, 0.16, 0.13, 0.16, 0.19],\n",
      "       [0.38, 0.23, 0.23, 0.53, 0.19, 0.27, 0.72],\n",
      "       [0.41, 0.99, 0.64, 0.3 , 0.33, 0.16, 0.47]])\n",
      " array([[0.24, 0.87, 0.1 , 0.65, 0.37, 0.02, 0.75],\n",
      "       [0.07, 0.44, 0.28, 0.49, 0.52, 0.44, 0.52]])]\n"
     ]
    }
   ],
   "source": [
    "derivatives_Cost_Weight = training()\n",
    "\n",
    "print(Weights)\n",
    "\n",
    "\n",
    "def gradient_descend(iterations = 10000, alpha = 0.01, dW_matrix = derivatives_Cost_Weight):\n",
    "\tdW_matrix = np.array(dW_matrix)\n",
    "\tfor i in range(len(derivatives_Cost_Weight)):\n",
    "\t\tdW_matrix[i] = np.array(dW_matrix[i])\n",
    "\n",
    "\tfor i in range(500):\n",
    "\t\tfor layer in range(len(dW_matrix)):\n",
    "\t\t\tfor m in range(len(dW_matrix[layer][:,0])):\n",
    "\t\t\t\tfor n in range(len(dW_matrix[layer][0,:])):\n",
    "\t\t\t\t\ta = dW_matrix[layer][m][n]\n",
    "\t\t\t\t\tj = Weights[layer][m][n]\n",
    "\t\t\t\t\tWeights[layer][m][n] = j - alpha*a\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.61      ,  0.41      ,  0.52      ,  0.06      ,  0.35      ,\n",
      "         0.72      ],\n",
      "       [-0.03722363,  0.53232409,  0.25407466,  0.46777525,  0.68447366,\n",
      "         0.0803803 ],\n",
      "       [ 0.56930456,  0.65949718,  0.25083137,  0.77874373,  0.59653077,\n",
      "         0.051383  ],\n",
      "       [ 0.43336686,  0.15795055,  0.27255031,  0.9200763 ,  0.20751122,\n",
      "         0.9472587 ],\n",
      "       [ 0.55346544,  0.76447104,  0.22513591,  0.64925833,  0.84857218,\n",
      "         0.22055315],\n",
      "       [ 0.02381971,  0.1389965 ,  0.02127578,  0.21942341,  0.60804806,\n",
      "         0.86591531],\n",
      "       [ 0.50723789,  0.09643043,  0.54086816,  0.80975952,  0.11552137,\n",
      "         0.17091503]])\n",
      " array([[0.4       , 0.8       , 0.01      , 0.49      , 0.43      ,\n",
      "        0.18      , 0.67      ],\n",
      "       [0.45348401, 0.21869489, 0.03023272, 0.76913341, 0.22895117,\n",
      "        0.52553735, 0.28262654],\n",
      "       [0.68240173, 0.50924399, 0.96697947, 0.15667414, 0.4466613 ,\n",
      "        0.87838329, 0.59756757],\n",
      "       [0.05863566, 0.15697594, 0.93421683, 0.90396111, 0.75384439,\n",
      "        0.98604454, 0.94497473],\n",
      "       [0.07930183, 0.70461724, 0.43940907, 0.06638098, 0.03693618,\n",
      "        0.0778824 , 0.10341252],\n",
      "       [0.30048892, 0.18043312, 0.17038785, 0.46878284, 0.12878354,\n",
      "        0.21633781, 0.6632293 ],\n",
      "       [0.34545445, 0.95014777, 0.59193848, 0.25043274, 0.28067519,\n",
      "        0.11661945, 0.42405091]])\n",
      " array([[ 0.24      ,  0.87      ,  0.1       ,  0.65      ,  0.37      ,\n",
      "         0.02      ,  0.75      ],\n",
      "       [-1.51513162, -0.97478887, -1.23927142, -1.05007989, -0.78141431,\n",
      "        -0.93609848, -0.92870142]])]\n"
     ]
    }
   ],
   "source": [
    "gradient_descend()\n",
    "print(Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat, w = forwardPropagation(i, False, False, neurons, Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n",
      "Network output:  0.0013637465562294918    Desired output:  0     -0.0005926718230810602\n",
      "[1 0 1 0 1]\n",
      "Network output:  0.0011480210513762678    Desired output:  1     -2.940050148163894\n",
      "[0 0 0 0 0]\n",
      "Network output:  0.0018584340689203702    Desired output:  0     -0.0008078585697875491\n",
      "[1 1 1 1 1]\n",
      "Network output:  0.0010330729211359786    Desired output:  1     -2.9858690220145223\n",
      "[0 0 0 0 1]\n",
      "Network output:  0.0015196631827462395    Desired output:  0     -0.0006604833179141169\n",
      "[0 1 0 1 0]\n",
      "Network output:  0.001314191757198564    Desired output:  1     -2.8813412610949825\n",
      "[1 0 1 1 0]\n",
      "Network output:  0.001138475733972842    Desired output:  1     -2.94367622171463\n",
      "[1 0 0 1 0]\n",
      "Network output:  0.0013034913106375508    Desired output:  1     -2.8848918595894317\n",
      "[0 1 1 1 0]\n",
      "Network output:  0.0011454852287130523    Desired output:  1     -2.94101050676247\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(desired_outputs_testing)):\n",
    "\tprint(inputs_testing[i])\n",
    "\tmat, w = forwardPropagation(i, False, False, mat, Weights)\n",
    "\tprint(\"Network output: \", mat[3][1], \"   Desired output: \", desired_outputs_testing[i], \"   \", CostFunction(mat[3][1], desired_outputs_testing[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n",
      "Network output:  0.0013637465562294918    Desired output:  0     -0.0005926718230810602\n",
      "[1 0 1 0 1]\n",
      "Network output:  0.0011480210513762678    Desired output:  1     -2.940050148163894\n",
      "[0 0 0 0 0]\n",
      "Network output:  0.0018584340689203702    Desired output:  0     -0.0008078585697875491\n",
      "[1 1 1 1 1]\n",
      "Network output:  0.0010330729211359786    Desired output:  1     -2.9858690220145223\n",
      "[0 0 0 0 1]\n",
      "Network output:  0.0015196631827462395    Desired output:  0     -0.0006604833179141169\n",
      "[0 1 0 1 0]\n",
      "Network output:  0.001314191757198564    Desired output:  1     -2.8813412610949825\n",
      "[1 0 1 1 0]\n",
      "Network output:  0.001138475733972842    Desired output:  1     -2.94367622171463\n",
      "[1 0 0 1 0]\n",
      "Network output:  0.0013034913106375508    Desired output:  1     -2.8848918595894317\n",
      "[0 1 1 1 0]\n",
      "Network output:  0.0011454852287130523    Desired output:  1     -2.94101050676247\n",
      "[1 0 1 0 0]\n",
      "Network output:  0.001261178289509545    Desired output:  1     -2.899223514000377\n",
      "[1 1 0 1 1]\n",
      "Network output:  0.0011056962536077036    Desired output:  0     -0.0004804634539002661\n",
      "[0 0 0 1 1]\n",
      "Network output:  0.001280856083135886    Desired output:  0     -0.000556625283606767\n",
      "[1 1 1 0 0]\n",
      "Network output:  0.0011755273299547163    Desired output:  1     -2.92976726946499\n",
      "[0 1 0 0 1]\n",
      "Network output:  0.0013551432418485913    Desired output:  0     -0.0005889303648129732\n",
      "[0 1 0 1 1]\n",
      "Network output:  0.0011827902508300078    Desired output:  1     -2.9270922638112733\n",
      "[0 1 1 0 1]\n",
      "Network output:  0.0011712900634525466    Desired output:  0     -0.0005089829528275388\n",
      "[1 1 1 0 1]\n",
      "Network output:  0.0010935765769860004    Desired output:  1     -2.9611508003739115\n",
      "[0 1 1 1 1]\n",
      "Network output:  0.0010751555981338677    Desired output:  1     -2.9685286794498738\n",
      "[1 0 1 1 1]\n",
      "Network output:  0.0010677000974450284    Desired output:  1     -2.971550717640043\n",
      "[1 0 0 0 1]\n",
      "Network output:  0.0013185354773276193    Desired output:  0     -0.0005730105324263904\n",
      "[1 0 0 0 0]\n",
      "Network output:  0.0015370383665184383    Desired output:  0     -0.000668040814854935\n",
      "[1 1 1 1 0]\n",
      "Network output:  0.0010850063952543996    Desired output:  1     -2.9645677019854877\n",
      "[0 1 0 0 0]\n",
      "Network output:  0.001582486592528256    Desired output:  1     -2.8006599608149747\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(training_data_set)):\n",
    "\tprint(inputs[i])\n",
    "\tmat, w = forwardPropagation(i, True, False, mat, Weights)\n",
    "\tprint(\"Network output: \", mat[3][1], \"   Desired output: \", desired_outputs[i], \"   \", CostFunction(mat[3][1], desired_outputs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
