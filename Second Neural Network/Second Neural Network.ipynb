{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 input neurons in the input layer\n",
    "# 2 hidden layers with 6 neurons each\n",
    "# 2 output neurons in the output layer\n",
    "# all activation functions are sigmoid\n",
    "\n",
    "\n",
    "dataset_unfiltered = np.array([\n",
    "\t[0,\t\t0,\t\t0,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t0,\t\t1,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t0,\t\t1,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t1,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t1,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t1,\t\t1,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t0,\t\t1,\t\t1,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t1,\t\t0,\t\t0,\t\t0,\t\t1,\t\t0],\n",
    "\t[0,\t\t1,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t1,\t\t0,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[0,\t\t1,\t\t0,\t\t1,\t\t1,\t\t1,\t\t0],\n",
    "\t[0,\t\t1,\t\t1,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[0,\t\t1,\t\t1,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[0,\t\t1,\t\t1,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[0,\t\t1,\t\t1,\t\t1,\t\t1,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t0,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[1,\t\t0,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[1,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t0,\t\t1,\t\t1,\t\t0,\t\t1],\n",
    "\t[1,\t\t0,\t\t1,\t\t0,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t1,\t\t0,\t\t1,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t1,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t0,\t\t1,\t\t1,\t\t1,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t0,\t\t0,\t\t0,\t\t0,\t\t1],\n",
    "\t[1,\t\t1,\t\t0,\t\t0,\t\t1,\t\t0,\t\t1],\n",
    "\t[1,\t\t1,\t\t0,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t0,\t\t1,\t\t1,\t\t0,\t\t1],\n",
    "\t[1,\t\t1,\t\t1,\t\t0,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t1,\t\t0,\t\t1,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t1,\t\t1,\t\t0,\t\t1,\t\t0],\n",
    "\t[1,\t\t1,\t\t1,\t\t1,\t\t1,\t\t1,\t\t0]\n",
    "\t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRandom2DMatrix(m, n):\n",
    "\treturn [ [random.randint(1,100)/100 for k in range(n)] for i in range(m) ]\n",
    "\n",
    "def sigmoid(z):\n",
    "\treturn 1/(1+np.exp(-z))\n",
    "\n",
    "def CostFunction(NN_output,output):\n",
    "\treturn output*(np.log10(NN_output)) + (1-output)*(np.log10(1 - NN_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = [ [0 for k in range(6)] for i in range(len(dataset_unfiltered)) ]\n",
    "index_data_set = 0\n",
    "\n",
    "\n",
    "\n",
    "for k in range(len(dataset_unfiltered[:,0])):\n",
    "\n",
    "\tfor i in range(dataset_unfiltered[k][5]):\n",
    "\t\t#temp = np.append( dataset_unfiltered[k][0:5], 1)\n",
    "\t\tdata_set[index_data_set] = np.append( dataset_unfiltered[k][0:5], 1)\n",
    "\t\tindex_data_set += 1\n",
    "\n",
    "\tfor j in range(dataset_unfiltered[k][6]):\n",
    "\t\t#temp = dataset_unfiltered[k][0:5]\n",
    "\t\tdata_set[index_data_set] = np.append( dataset_unfiltered[k][0:5], 0)\n",
    "\t\tindex_data_set += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training dataset and testing dataset:\n",
    "# But first, we need to shuffle the entire dataset!\n",
    "\n",
    "random.seed(99)\n",
    "random.shuffle(data_set)\n",
    "\n",
    "training_data_set = data_set[0:(math.ceil(0.70*len(data_set)))]\n",
    "testing_data_set  =\tdata_set[(math.ceil(0.70*len(data_set))): len(data_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:    23\n",
      "Testing dataset:     9\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset:   \", len(training_data_set))\n",
    "print(\"Testing dataset:    \", len(testing_data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [ [0 for k in range(5)] for i in range(len(training_data_set)) ]\n",
    "desired_outputs = [0 for k in range(len(training_data_set))]\n",
    "\n",
    "\n",
    "inputs_testing = [ [0 for k in range(5)] for i in range(len(testing_data_set)) ]\n",
    "desired_outputs_testing = [0 for k in range(len(testing_data_set))]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(training_data_set)):\n",
    "\tinputs[i] = training_data_set[i][0:5]\n",
    "\tdesired_outputs[i] = training_data_set[i][5]\n",
    "\n",
    "for i in range(len(testing_data_set)):\n",
    "\tinputs_testing[i] = training_data_set[i][0:5]\n",
    "\tdesired_outputs_testing[i] = training_data_set[i][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_space = 1\n",
    "\n",
    "nInputs_neurons = 5 \n",
    "nNeurons_second_layer = 6 \n",
    "nNeurons_third_layer  = 6 \n",
    "output_neurons = 1 \n",
    "\n",
    "nInputs_neurons += bias_space\n",
    "nNeurons_second_layer += bias_space\n",
    "nNeurons_third_layer  += bias_space\n",
    "output_neurons += bias_space     # Not needed but will does make the algorith easier to write. We will ignore the bias here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights = [ [] for i in range(3)]\n",
    "\n",
    "#the first column is the Bias. So it will be set to 1.\n",
    "Weights[0] = np.array(generateRandom2DMatrix(nNeurons_second_layer, nInputs_neurons ))\n",
    "Weights[1] = np.array(generateRandom2DMatrix(nNeurons_third_layer, nNeurons_second_layer ))\n",
    "Weights[2] = np.array(generateRandom2DMatrix(output_neurons, nNeurons_third_layer ))\n",
    "\n",
    "Weights = np.array(Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = [ 0 for i in range(nInputs_neurons)]\n",
    "first_hidden_layer = [ 0 for i in range(nNeurons_second_layer)]\n",
    "second_hidden_layer = [ 0 for i in range(nNeurons_third_layer)]\n",
    "output_layer = [ 0 for i in range(output_neurons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are bias\n",
    "input_layer = np.append(1, inputs[0])\n",
    "first_hidden_layer[0] = 1\n",
    "second_hidden_layer[0] = 1\n",
    "\n",
    "neurons = [input_layer, first_hidden_layer, second_hidden_layer, output_layer]\n",
    "neurons = (neurons)\n",
    "#neuron[\"layer\"][\"Which neuron of the layer/ FIRST ONE IS THE BIAS\"]\n",
    "neurons[0][0] = 1\n",
    "neurons[1][0] = 1\n",
    "neurons[2][0] = 1\n",
    "neurons[3][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropagation(data_number = 0, training_data = True, showComputation = False, matrix_neurons = neurons, W = Weights):\n",
    "\tif(training_data == True):\n",
    "\t\tinput_i = inputs[data_number]\n",
    "\telse:\n",
    "\t\tinput_i = inputs_testing[data_number]\n",
    "\n",
    "\tmatrix_neurons[0] = np.append(1 , input_i)\n",
    "\tmatrix_neurons[1][0] = 1\n",
    "\tmatrix_neurons[2][0] = 1\n",
    "\tmatrix_neurons[3][0] = 1\n",
    "\t\n",
    "\tif(showComputation == True):\n",
    "\t\tprint(matrix_neurons)\n",
    "\n",
    "\tfor layer in range(len(W)):\n",
    "\t\tfor neuron_j in range(len(matrix_neurons[layer+1])):\n",
    "\t\t\tnext_layer_neuron = layer + 1\n",
    "\t\t\tz_j = np.dot( matrix_neurons[layer] , W[layer][neuron_j,:] )\n",
    "\t\t\tmatrix_neurons[next_layer_neuron][neuron_j] = sigmoid(z_j)\n",
    "\t\t\tif(showComputation == True):\n",
    "\t\t\t\tprint(matrix_neurons[layer] ,\" . \" , W[layer][neuron_j,:], \"  = s([\",next_layer_neuron, \"][\",neuron_j,\"]]) = \", sigmoid(z_j))\n",
    "\t\t\t\tprint(\"\")\n",
    "\n",
    "\tmatrix_neurons[1][0] = 1\n",
    "\tmatrix_neurons[2][0] = 1\n",
    "\tmatrix_neurons[3][0] = 1\n",
    "\n",
    "\treturn matrix_neurons, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs         :         [1 1 1 0 0 0]\n",
      "Hidden layer 1 :         [1, 0.6963549298238342, 0.8220063142137535, 0.7130001627522816, 0.8277836082661223, 0.5572478545985555, 0.7685247834990178]\n",
      "Hidden layer 2 :         [1, 0.8872244509440987, 0.9612400717011033, 0.9721735867571986, 0.8320721031373728, 0.8700163598547583, 0.9234753293152094]\n",
      "Outputs        :         [1, 0.923769115516216]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "forwardPropagation(0)\n",
    "\n",
    "\n",
    "def printNeurons(matrix_neurons = neurons):\n",
    "\tlayer_names = [\"Inputs        \", \"Hidden layer 1\", \"Hidden layer 2\", \"Outputs       \"]\n",
    "\tfor i in range(len(matrix_neurons)):\n",
    "\t\tprint(layer_names[i] , \":        \", matrix_neurons[i])\n",
    "        \n",
    "    \n",
    "printNeurons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing delta\n",
    "def get_copy_of_neurons_matrix_null(matrix):\n",
    "\tm = matrix.copy()\n",
    "\tfor i in range(len(m)):\n",
    "\t\tm[i] = np.matrix(m[i])\n",
    "\t\tm[i].fill(0)\n",
    "\treturn m\n",
    "\n",
    "\n",
    "\n",
    "delta_error_matrix = get_copy_of_neurons_matrix_null(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDeltaMatrix(training_example = 0, showComputation = False, W = Weights, matrix_neurons = neurons, Delt = delta_error_matrix):\n",
    "\t\n",
    "\tif(showComputation == True):\n",
    "\t\tprint(\"STARTING: \")\n",
    "\t#training_example = 1000\n",
    "\tinput_i = inputs[training_example] \n",
    "\tdesired_outputs_i = desired_outputs[training_example]\n",
    "\n",
    "\tif(showComputation == True):\n",
    "\t\tprint(W)\n",
    "\t\tprint(\"Training example: \", training_example)\n",
    "\t\tprint(\"Inputs and outputs: \", input_i, desired_outputs_i)\n",
    "\n",
    "\tfor layer in reversed(range(1,len(matrix_neurons))):\n",
    "\t\tif(showComputation == True):\n",
    "\t\t\tprint(layer)\n",
    "\t\tif(layer == len(matrix_neurons) - 1):\n",
    "\t\t\tif(showComputation == True):\n",
    "\t\t\t\tprint(np.subtract(matrix_neurons[layer][1:len(matrix_neurons[layer])] , desired_outputs_i))\n",
    "\t\t\tDelt[layer] = np.subtract(matrix_neurons[layer][1:len(matrix_neurons[layer])] , desired_outputs_i)\n",
    "\t\t\tDelt[layer] = np.append(0, Delt[layer])\n",
    "\t\telse:\n",
    "\t\t\t\tw = W[layer].copy() #[1:len(W[layer])].copy()\n",
    "\t\t\t\t\n",
    "\t\t\t\tw_T = w.transpose() \n",
    "\t\t\t\tif(showComputation == True):\n",
    "\t\t\t\t\tprint(\"w: \", w)\n",
    "\t\t\t\t\tprint(\"w_T:\")\n",
    "\t\t\t\t\tprint(w_T)\n",
    "\t\t\t\t\tprint(\"delta \",layer + 1,\":\" )\n",
    "\t\t\t\t\tprint(Delt[layer + 1])\n",
    "\t\t\t\tx = np.matmul(w_T, Delt[layer + 1])\n",
    "\t\t\t\t#x = x[1:len(x)]\n",
    "\n",
    "\t\t\t\t# Derivative_Sigmoid_of_neuron_layer(z) = neurons_of_layer*(1-neurons_of_layer)\n",
    "\t\t\t\tneurons_of_layer = np.array(matrix_neurons[layer].copy())#[1:len(matrix_neurons[layer])].copy())\n",
    "\t\t\t\tvector_of_one \t = np.array(neurons_of_layer.copy())\n",
    "\t\t\t\tvector_of_one.fill(1)\n",
    "\t\t\t\ty = np.subtract(vector_of_one, neurons_of_layer)\n",
    "\t\t\t\tDerivative_Sigmoid_of_neuron_layer = np.multiply(neurons_of_layer , y)\n",
    "\n",
    "\t\t\t\t# Putting the whole equation together:\n",
    "\t\t\t\tDelt[layer] = np.multiply(x , Derivative_Sigmoid_of_neuron_layer)\n",
    "\t\tif(showComputation == True):\n",
    "\t\t\tprint(\"delta[\",layer,\"]\", Delt[layer])\n",
    "\treturn Delt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = computeDeltaMatrix() \n",
    "#print(np.matrix(delta))\n",
    "\n",
    "\n",
    "def training(nomber_of_training_set = len(training_data_set), matrix_neurons = neurons, W = Weights, regularization_param = 0):\n",
    "\tmat_weights_null = get_copy_of_neurons_matrix_null(W)\n",
    "\t\n",
    "\tfor training_set in range(nomber_of_training_set):\n",
    "\t\t#print(training_set)\n",
    "\t\tmatrix_neurons, W \t= forwardPropagation(training_set, True, False, matrix_neurons, W)\n",
    "\t\tdelta \t\t\t\t= computeDeltaMatrix(training_set)\n",
    "\n",
    "\t\t# Backpropagation algorithm\n",
    "\t\tfor layer in reversed(range(1, len(matrix_neurons))):\n",
    "\t\t\tneuron_vector = neurons[layer-1].copy()\n",
    "\t\t\tdelta_vector  = delta[layer].copy()\n",
    "\n",
    "\t\t\tneuron_vector = np.matrix(neuron_vector)\n",
    "\t\t\tdelta_vector  = np.matrix(delta_vector).transpose()\n",
    "\n",
    "\t\t\tmultiplication_term = np.matmul(delta_vector, neuron_vector)\n",
    "\t\t\tmat_weights_null[layer-1] = mat_weights_null[layer-1] + multiplication_term\n",
    "\n",
    "\tc = (1/nomber_of_training_set)\n",
    "\t#derivative_J = (1/nomber_of_training_set)*mat_weights_null\n",
    "\tderivatives_Cost_Weight = get_copy_of_neurons_matrix_null(W)\n",
    "\n",
    "\tfor layer in range(len(mat_weights_null)):\n",
    "\t\tfor m in range(len(mat_weights_null[layer][:,0])):\n",
    "\t\t\tfor n in range(len(mat_weights_null[layer][0,:])):\n",
    "\t\t\t\tif(n != 0):\n",
    "\t\t\t\t\tderivatives_Cost_Weight[layer][m][n] = c*mat_weights_null[layer][m][n] #+ regularization_param*W[layer][m][n]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tderivatives_Cost_Weight[layer][m][n] = c*mat_weights_null[layer][m][n]\n",
    "\treturn derivatives_Cost_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  0.61      ,   0.41      ,   0.52      ,   0.06      ,\n",
      "          0.35      ,   0.72      ],\n",
      "       [ -2.62110604,  -1.64718624,  -0.91529618,  -1.94527309,\n",
      "         -1.01534079,  -1.54621229],\n",
      "       [-34.84471769, -20.02698368, -23.02886515, -21.54699888,\n",
      "        -20.78502002, -15.78393808],\n",
      "       [ 15.82406266,   9.42698631,  10.80432239,  11.9157419 ,\n",
      "          9.4569715 ,   6.08592847],\n",
      "       [  3.22140778,   1.32901867,   2.48086026,   1.03213979,\n",
      "          1.60760115,   0.20588913],\n",
      "       [-49.13423317, -31.2894703 , -31.47048948, -33.6384943 ,\n",
      "        -30.07376672, -19.74137359],\n",
      "       [-29.66197329, -19.18986969, -18.1118989 , -19.26222573,\n",
      "        -18.81921246, -13.03533483]])\n",
      " array([[ 4.00000000e-01,  8.00000000e-01,  1.00000000e-02,\n",
      "         4.90000000e-01,  4.30000000e-01,  1.80000000e-01,\n",
      "         6.70000000e-01],\n",
      "       [-8.56972587e+01, -3.41771705e+01, -6.14602287e+01,\n",
      "        -5.95494089e+01, -7.00238895e+01, -4.46715388e+01,\n",
      "        -5.26143302e+01],\n",
      "       [-2.52372716e+02, -1.02035264e+02, -1.83103663e+02,\n",
      "        -1.80306688e+02, -2.09297280e+02, -1.33480321e+02,\n",
      "        -1.56582137e+02],\n",
      "       [-2.35157637e+02, -9.52323065e+01, -1.69521140e+02,\n",
      "        -1.65177091e+02, -1.93579449e+02, -1.23172952e+02,\n",
      "        -1.44310503e+02],\n",
      "       [-5.35111387e+01, -1.24870364e+00, -2.00267131e+00,\n",
      "        -1.62186679e+01, -5.27136356e+01, -1.99539420e+00,\n",
      "        -2.17819610e+00],\n",
      "       [-2.95198276e+01, -1.17740804e+01, -2.07767737e+01,\n",
      "        -1.99613388e+01, -2.37084793e+01, -1.51323514e+01,\n",
      "        -1.75957994e+01],\n",
      "       [-1.13228990e+02, -4.53786538e+01, -8.14057939e+01,\n",
      "        -7.89543974e+01, -9.29296806e+01, -5.90407957e+01,\n",
      "        -6.95839344e+01]])\n",
      " array([[ 2.40000000e-01,  8.70000000e-01,  1.00000000e-01,\n",
      "         6.50000000e-01,  3.70000000e-01,  2.00000000e-02,\n",
      "         7.50000000e-01],\n",
      "       [ 1.18104565e+01, -2.46225888e+01,  2.06584140e+01,\n",
      "         2.13726553e+01, -2.34243120e+01, -2.60137619e+01,\n",
      "        -2.41864722e+01]])]\n"
     ]
    }
   ],
   "source": [
    "derivatives_Cost_Weight = training()\n",
    "\n",
    "print(Weights)\n",
    "\n",
    "\n",
    "def gradient_descend(iterations = 60000, alpha = 0.01, dW_matrix = derivatives_Cost_Weight):\n",
    "\tdW_matrix = np.array(dW_matrix)\n",
    "\tfor i in range(len(derivatives_Cost_Weight)):\n",
    "\t\tdW_matrix[i] = np.array(dW_matrix[i])\n",
    "\n",
    "\tfor i in range(iterations):\n",
    "\t\tfor layer in range(len(dW_matrix)):\n",
    "\t\t\tfor m in range(len(dW_matrix[layer][:,0])):\n",
    "\t\t\t\tfor n in range(len(dW_matrix[layer][0,:])):\n",
    "\t\t\t\t\ta = dW_matrix[layer][m][n]\n",
    "\t\t\t\t\tj = Weights[layer][m][n]\n",
    "\t\t\t\t\tWeights[layer][m][n] = j - alpha*a\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  0.61      ,   0.41      ,   0.52      ,   0.06      ,\n",
      "          0.35      ,   0.72      ],\n",
      "       [ -2.62110604,  -1.64718624,  -0.91529618,  -1.94527309,\n",
      "         -1.01534079,  -1.54621229],\n",
      "       [-34.84471769, -20.02698368, -23.02886515, -21.54699888,\n",
      "        -20.78502002, -15.78393808],\n",
      "       [ 15.82406266,   9.42698631,  10.80432239,  11.9157419 ,\n",
      "          9.4569715 ,   6.08592847],\n",
      "       [  3.22140778,   1.32901867,   2.48086026,   1.03213979,\n",
      "          1.60760115,   0.20588913],\n",
      "       [-49.13423317, -31.2894703 , -31.47048948, -33.6384943 ,\n",
      "        -30.07376672, -19.74137359],\n",
      "       [-29.66197329, -19.18986969, -18.1118989 , -19.26222573,\n",
      "        -18.81921246, -13.03533483]])\n",
      " array([[ 4.00000000e-01,  8.00000000e-01,  1.00000000e-02,\n",
      "         4.90000000e-01,  4.30000000e-01,  1.80000000e-01,\n",
      "         6.70000000e-01],\n",
      "       [-8.56972587e+01, -3.41771705e+01, -6.14602287e+01,\n",
      "        -5.95494089e+01, -7.00238895e+01, -4.46715388e+01,\n",
      "        -5.26143302e+01],\n",
      "       [-2.52372716e+02, -1.02035264e+02, -1.83103663e+02,\n",
      "        -1.80306688e+02, -2.09297280e+02, -1.33480321e+02,\n",
      "        -1.56582137e+02],\n",
      "       [-2.35157637e+02, -9.52323065e+01, -1.69521140e+02,\n",
      "        -1.65177091e+02, -1.93579449e+02, -1.23172952e+02,\n",
      "        -1.44310503e+02],\n",
      "       [-5.35111387e+01, -1.24870364e+00, -2.00267131e+00,\n",
      "        -1.62186679e+01, -5.27136356e+01, -1.99539420e+00,\n",
      "        -2.17819610e+00],\n",
      "       [-2.95198276e+01, -1.17740804e+01, -2.07767737e+01,\n",
      "        -1.99613388e+01, -2.37084793e+01, -1.51323514e+01,\n",
      "        -1.75957994e+01],\n",
      "       [-1.13228990e+02, -4.53786538e+01, -8.14057939e+01,\n",
      "        -7.89543974e+01, -9.29296806e+01, -5.90407957e+01,\n",
      "        -6.95839344e+01]])\n",
      " array([[ 2.40000000e-01,  8.70000000e-01,  1.00000000e-01,\n",
      "         6.50000000e-01,  3.70000000e-01,  2.00000000e-02,\n",
      "         7.50000000e-01],\n",
      "       [-2.22911243e+02, -2.46225888e+01,  2.06584140e+01,\n",
      "         2.13726553e+01, -2.34243120e+01, -2.60137619e+01,\n",
      "        -2.41864722e+01]])]\n"
     ]
    }
   ],
   "source": [
    "gradient_descend()\n",
    "print(Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat, w = forwardPropagation(0, False, False, neurons, Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n",
      "Network output:  0.9998976846373853    Desired output:  0     -3.9900591522322135\n",
      "[1 0 1 0 1]\n",
      "Network output:  0.9998995050090798    Desired output:  1     -4.3646613185311055e-05\n",
      "[0 0 0 0 0]\n",
      "Network output:  0.9998896782574364    Desired output:  0     -3.95733888697181\n",
      "[1 1 1 1 1]\n",
      "Network output:  0.9999057404301642    Desired output:  1     -4.0938340491746004e-05\n",
      "[0 0 0 0 1]\n",
      "Network output:  0.9998937391744854    Desired output:  0     -3.973626814484723\n",
      "[0 1 0 1 0]\n",
      "Network output:  0.9998977733281047    Desired output:  1     -4.4398748914299e-05\n",
      "[1 0 1 1 0]\n",
      "Network output:  0.9998954730349672    Desired output:  1     -4.539785681528253e-05\n",
      "[1 0 0 1 0]\n",
      "Network output:  0.9998952724871705    Desired output:  1     -4.5484962730399734e-05\n",
      "[0 1 1 1 0]\n",
      "Network output:  0.9998970602457488    Desired output:  1     -4.4708468418648636e-05\n"
     ]
    }
   ],
   "source": [
    "x = [-1/10000000 for i in range(len(desired_outputs_testing))]\n",
    "x = np.array(x)\n",
    "y = x.copy()\n",
    "\n",
    "\n",
    "for i in range(len(desired_outputs_testing)):\n",
    "\tprint(inputs_testing[i])\n",
    "\tmat, w = forwardPropagation(i, False, False, mat, Weights)\n",
    "\tx[i] = mat[3][1]\n",
    "\ty[i] = desired_outputs_testing[i]\n",
    "\tprint(\"Network output: \", mat[3][1], \"   Desired output: \", desired_outputs_testing[i], \"   \", CostFunction(mat[3][1], desired_outputs_testing[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99989768 0.99989951 0.99988968 0.99990574 0.99989374 0.99989777\n",
      " 0.99989547 0.99989527 0.99989706]\n",
      "[0. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "[0.99988968 0.99989374 0.99989527 0.99989547 0.99989706 0.99989768\n",
      " 0.99989777 0.99989951 0.99990574]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "\n",
    "x.sort()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n",
      "Network output:  2.3804422038609128e-35    Desired output:  0     0.0\n",
      "[1 0 1 0 1]\n",
      "Network output:  2.5156626786512466e-36    Desired output:  1     -35.5993475932036\n",
      "[0 0 0 0 0]\n",
      "Network output:  2.2715766724974286e-35    Desired output:  0     0.0\n",
      "[1 1 1 1 1]\n",
      "Network output:  4.974514478863501e-37    Desired output:  1     -36.30324930073538\n",
      "[0 0 0 0 1]\n",
      "Network output:  3.5722059762244084e-35    Desired output:  0     0.0\n",
      "[0 1 0 1 0]\n",
      "Network output:  5.6352551957549444e-36    Desired output:  1     -35.24908641189851\n",
      "[1 0 1 1 0]\n",
      "Network output:  6.048405246159052e-37    Desired output:  1     -36.21835911858578\n",
      "[1 0 0 1 0]\n",
      "Network output:  6.024398207854096e-36    Desired output:  1     -35.22008632934421\n",
      "[0 1 1 1 0]\n",
      "Network output:  5.894026684845551e-37    Desired output:  1     -36.22958790223992\n",
      "[1 0 1 0 0]\n",
      "Network output:  2.2638425339683495e-36    Desired output:  1     -35.64515378464232\n",
      "[1 1 0 1 1]\n",
      "Network output:  4.467084489662262e-36    Desired output:  0     0.0\n",
      "[0 0 0 1 1]\n",
      "Network output:  8.016619253423392e-36    Desired output:  0     0.0\n",
      "[1 1 1 0 0]\n",
      "Network output:  1.969419239675786e-36    Desired output:  1     -35.70566182368058\n",
      "[0 1 0 0 1]\n",
      "Network output:  2.997844716836326e-35    Desired output:  0     0.0\n",
      "[0 1 0 1 1]\n",
      "Network output:  5.890860548056663e-36    Desired output:  1     -35.229821258018774\n",
      "[0 1 1 0 1]\n",
      "Network output:  2.591982964068331e-36    Desired output:  0     0.0\n",
      "[1 1 1 0 1]\n",
      "Network output:  1.956373645016064e-36    Desired output:  1     -35.70854819634206\n",
      "[0 1 1 1 1]\n",
      "Network output:  6.141089153463532e-37    Desired output:  1     -36.21175459768766\n",
      "[1 0 1 1 1]\n",
      "Network output:  6.332447531624059e-37    Desired output:  1     -36.198428399929924\n",
      "[1 0 0 0 1]\n",
      "Network output:  3.320110588514434e-35    Desired output:  0     0.0\n",
      "[1 0 0 0 0]\n",
      "Network output:  2.7421380615534757e-35    Desired output:  0     0.0\n",
      "[1 1 1 1 0]\n",
      "Network output:  5.1808445457663256e-37    Desired output:  1     -36.285599438774206\n",
      "[0 1 0 0 0]\n",
      "Network output:  2.4757134473430366e-35    Desired output:  1     -34.606299624369036\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(training_data_set)):\n",
    "\tprint(inputs[i])\n",
    "\tmat, w = forwardPropagation(i, True, False, mat, Weights)\n",
    "\tprint(\"Network output: \", mat[3][1], \"   Desired output: \", desired_outputs[i], \"   \", CostFunction(mat[3][1], desired_outputs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
